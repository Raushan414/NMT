{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: indic-nlp-library in c:\\users\\raushan\\anaconda3\\lib\\site-packages (0.71)\n",
      "Requirement already satisfied: morfessor in c:\\users\\raushan\\anaconda3\\lib\\site-packages (from indic-nlp-library) (2.0.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\raushan\\anaconda3\\lib\\site-packages (from indic-nlp-library) (1.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\raushan\\anaconda3\\lib\\site-packages (from indic-nlp-library) (1.16.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\raushan\\anaconda3\\lib\\site-packages (from pandas->indic-nlp-library) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\raushan\\anaconda3\\lib\\site-packages (from pandas->indic-nlp-library) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\raushan\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->indic-nlp-library) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install indic-nlp-library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import indicnlp\n",
    "import string\n",
    "import sys\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "from indicnlp import common\n",
    "from indicnlp import loader\n",
    "from indicnlp.normalize.indic_normalize import IndicNormalizerFactory\n",
    "from indicnlp.tokenize import indic_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "line = 'á'\n",
    "line = normalize('NFC',line).encode('ASCII','ignore')\n",
    "line = line.decode('utf-8')\n",
    "print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('raw_data.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sharaabi</td>\n",
       "      <td>शराबी</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politicians do not have permission to do what ...</td>\n",
       "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'd like to tell you about one such child,</td>\n",
       "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This percentage is even greater than the perce...</td>\n",
       "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what we really mean is that they're bad at not...</td>\n",
       "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             English  \\\n",
       "0                                           Sharaabi   \n",
       "1  politicians do not have permission to do what ...   \n",
       "2         I'd like to tell you about one such child,   \n",
       "3  This percentage is even greater than the perce...   \n",
       "4  what we really mean is that they're bad at not...   \n",
       "\n",
       "                                               Hindi  \n",
       "0                                              शराबी  \n",
       "1  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
       "2  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
       "3   यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n",
       "4     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327637, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English    0\n",
       "Hindi      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Username and/or password invalid. Please try again'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['English'][1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'उपयोक्तानाम और/या कूटशब्द अवैध. कृपया फिर कोशिश करें'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Hindi'][1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace(u',',' ')\n",
    "    text = text.replace(u'.',' ')\n",
    "    text = text.replace(u'|',' ')\n",
    "    text = text.replace(u'।',' ')\n",
    "    text = text.replace(u' |','')\n",
    "    text = text.replace(u'/',' ')\n",
    "    text = text.replace(u';','')\n",
    "    text = text.replace(u':','')\n",
    "    text = text.replace(u'(',' ')\n",
    "    text = text.replace(u')',' ')\n",
    "    text = text.replace(u'!',' ')\n",
    "    text = text.replace(u'\"',' ')\n",
    "    text = text.replace(u'-','')\n",
    "    text = text.replace(u'_',' ')\n",
    "    text=text.replace(u\"‘‘\",' ')\n",
    "    text=text.replace(u\"’’\",' ')\n",
    "    text=text.replace(u\"?\",' ')\n",
    "    text=text.replace(u\"\\\\\",' ')\n",
    "    text= re.sub(\"'\", '', text)\n",
    "    text = re.sub('[0-9+\\-*/.%]','',text) #check for digit and some signs\n",
    "    pun = set(string.punctuation)\n",
    "    text = text.strip() #removing age and piche ka whitespace if present\n",
    "    text=re.sub(' +', ' ',text) #removing extra whitespaces between words\n",
    "    text = ''.join(word for word in text if word not in pun)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'उपयोक्तानाम और या कूटशब्द अवैध कृपया फिर कोशिश करें'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text('उपयोक्तानाम और/या कूटशब्द अवैध. कृपया फिर कोशिश करें|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Username and or password invalid Please try again'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text('Username and/or password invalid. Please try again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_english(line):\n",
    "    line = line.lower()\n",
    "    line = clean_text(line)\n",
    "    line = normalize('NFC',line).encode('ASCII','ignore') #normalizing the text basically normal form decomposition if other\n",
    "    #than ascii characters are there we will ignore them like greek character\n",
    "    line = line.decode('utf-8') #decoding the text in utf-8 format\n",
    "    line = line.split()\n",
    "    line = [word for word in line if word.isalpha()] #if not [a-z] isalpha() return false\n",
    "    line = ' '.join(line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'username and or password invalid please try again'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_english('Username and/or password invalid. Please try again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_hindi(line):\n",
    "    line = re.sub('[a-zA-Z]','',line)\n",
    "    line = clean_text(line)\n",
    "    factory=IndicNormalizerFactory() #normalizing the hindi text\n",
    "    normalizer=factory.get_normalizer(language = \"hi\",remove_nuktas=False)\n",
    "    line = normalizer.normalize(line)\n",
    "    token = []\n",
    "    \n",
    "    for tok in indic_tokenize.trivial_tokenize(line,lang=\"hi\"): #tokenizing the text\n",
    "        token.append(tok)\n",
    "    line = token\n",
    "    line = [word for word in line if not re.search(r'\\d', word)] #check for digits\n",
    "    line = ' '.join(line)\n",
    "    line = 'START_ '+ line + ' _END'\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'START_ यह एक छोटी तीन गुम्बद वाली तराशे हुए श्वेत संगमर्मर से निर्मित है _END'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_hindi('यह एक छोटी तीन गुम्बद वाली तराशे हुए श्वेत संगमर्मर से निर्मित है।')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(df):\n",
    "    preprocessed_text = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        eng_text = preprocess_english(df['English'][i])\n",
    "        hin_text = preprocess_hindi(df['Hindi'][i])\n",
    "        preprocessed_text.append((eng_text,hin_text))\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = process_text(df)\n",
    "\n",
    "cleaned_df = pd.DataFrame(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sharaabi</td>\n",
       "      <td>START_ शराबी _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politicians do not have permission to do what ...</td>\n",
       "      <td>START_ राजनीतिज्ञों के पास जो कार्य करना चाहिए...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id like to tell you about one such child</td>\n",
       "      <td>START_ मई आपको ऐसे ही एक बच्चे के बारे में बता...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this percentage is even greater than the perce...</td>\n",
       "      <td>START_ यह प्रतिशत भारत में हिन्दुओं प्रतिशत से...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what we really mean is that theyre bad at not ...</td>\n",
       "      <td>START_ हम ये नहीं कहना चाहते कि वो ध्यान नहीं ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0                                           sharaabi   \n",
       "1  politicians do not have permission to do what ...   \n",
       "2           id like to tell you about one such child   \n",
       "3  this percentage is even greater than the perce...   \n",
       "4  what we really mean is that theyre bad at not ...   \n",
       "\n",
       "                                                   1  \n",
       "0                                  START_ शराबी _END  \n",
       "1  START_ राजनीतिज्ञों के पास जो कार्य करना चाहिए...  \n",
       "2  START_ मई आपको ऐसे ही एक बच्चे के बारे में बता...  \n",
       "3  START_ यह प्रतिशत भारत में हिन्दुओं प्रतिशत से...  \n",
       "4  START_ हम ये नहीं कहना चाहते कि वो ध्यान नहीं ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.rename(columns = {0:'english',1:'hindi'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sharaabi</td>\n",
       "      <td>START_ शराबी _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politicians do not have permission to do what ...</td>\n",
       "      <td>START_ राजनीतिज्ञों के पास जो कार्य करना चाहिए...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id like to tell you about one such child</td>\n",
       "      <td>START_ मई आपको ऐसे ही एक बच्चे के बारे में बता...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this percentage is even greater than the perce...</td>\n",
       "      <td>START_ यह प्रतिशत भारत में हिन्दुओं प्रतिशत से...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what we really mean is that theyre bad at not ...</td>\n",
       "      <td>START_ हम ये नहीं कहना चाहते कि वो ध्यान नहीं ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english  \\\n",
       "0                                           sharaabi   \n",
       "1  politicians do not have permission to do what ...   \n",
       "2           id like to tell you about one such child   \n",
       "3  this percentage is even greater than the perce...   \n",
       "4  what we really mean is that theyre bad at not ...   \n",
       "\n",
       "                                               hindi  \n",
       "0                                  START_ शराबी _END  \n",
       "1  START_ राजनीतिज्ञों के पास जो कार्य करना चाहिए...  \n",
       "2  START_ मई आपको ऐसे ही एक बच्चे के बारे में बता...  \n",
       "3  START_ यह प्रतिशत भारत में हिन्दुओं प्रतिशत से...  \n",
       "4  START_ हम ये नहीं कहना चाहते कि वो ध्यान नहीं ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "english    0\n",
       "hindi      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of bollywood films of\n",
      "START_ की बॉलीवुड फिल्में _END\n",
      "stack overflow\n",
      "START_ स्टैक ओवरफ़्लो _END\n",
      "humans destroyed the commons that they depended on\n",
      "START_ मानवों ने उन ही साझे संसाधनों को नष्ट किया जिन पर वो आधारित थे _END\n",
      "almost goes to e but otherwise the play would be over\n",
      "START_ रचना करीब करीब ई तक जाती है मगर तब तो नाटक ख़त्म हो जाएगा _END\n",
      "failed to activate configuration server s\n",
      "START_ विन्यास सर्वर को सक्रिय करने में विफल _END\n",
      "aryans did not make any statues or temples for deities\n",
      "START_ आर्य देवताओं की कोई मूर्ति या मन्दिर नहीं बनाते थे _END\n",
      "your system uses an arm cpu that is older than the armv architecture all packages in karmic were built with optimizations requiring armv as the minimal architecture it is not possible to upgrade your system to a new elementary os release with this hardware\n",
      "START_ आपका तंत्र सीपीयु का उपयोग कर रहा है जो संरचना से ज्यादा पुराना है कार्मिक के सभी पैकेज इस आशावादिता के साथ बनाए गए है कि न्यूनतम संरचना की आवश्यकता होगी इन हार्डवेयर के साथ उबुन्टू के नए प्रकाशन द्वारा अपने तंत्र को उन्नत करना संभव नहीं है _END\n",
      "\n",
      "START_ जनवरी _END\n",
      "comment on this item s name s email address optional s title of comments s comments\n",
      "START_ फिर भी मैं एक बात से चिंतित हूँ हालाँकि बहुत नहीं _END\n",
      "it has three small domes and has been constructed using white marble\n",
      "START_ यह एक छोटी तीन गुम्बद वाली तराशे हुए श्वेत संगमर्मर से निर्मित है _END\n"
     ]
    }
   ],
   "source": [
    "for i in range(100,110):\n",
    "    print(cleaned_df['english'][i])\n",
    "    print(cleaned_df['hindi'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Bollywood films of 2013\n",
      "2013 की बॉलीवुड फिल्में\n",
      "Stack overflow\n",
      "स्टैक ओवरफ़्लो\n",
      "humans destroyed the commons that they depended on.\n",
      "मानवों ने उन ही साझे संसाधनों को नष्ट किया जिन पर वो आधारित थे।\n",
      "Almost goes to E, but otherwise the play would be over.\n",
      "रचना करीब करीब ई तक जाती है, मगर तब तो नाटक ख़त्म हो जाएगा.\n",
      "Failed to activate configuration server: %s \n",
      "विन्यास सर्वर को सक्रिय करने में विफल: %s\n",
      "Aryans did not make any statues or temples for deities.\n",
      "आर्य देवताओं की कोई मूर्ति या मन्दिर नहीं बनाते थे।\n",
      "Your system uses an ARM CPU that is older than the ARMv6 architecture. All packages in karmic were built with optimizations requiring ARMv6 as the minimal architecture. It is not possible to upgrade your system to a new elementary OS release with this hardware.\n",
      "आपका तंत्र ARM सीपीयु का उपयोग कर रहा है जो ARMv6 संरचना से ज्यादा पुराना है. 'कार्मिक' के सभी पैकेज इस आशावादिता के साथ बनाए गए है कि न्यूनतम संरचना ARMv6 की आवश्यकता होगी. इन हार्डवेयर के साथ उबुन्टू के नए प्रकाशन द्वारा अपने तंत्र को उन्नत करना संभव नहीं है.\n",
      "2021-01-01 00:00:00\n",
      "२१ जनवरी\n",
      "Comment on this item <s> Name <s> Email Address (optional) <s> Title of Comments <s> Comments:\n",
      "फिर भी मैं एक बात से चिंतित हूँ हालाँकि बहुत नहीं।\n",
      "It has three small domes and has been constructed using white marble.\n",
      "यह एक छोटी तीन गुम्बद वाली तराशे हुए श्वेत संगमर्मर से निर्मित है।\n"
     ]
    }
   ],
   "source": [
    "for i in range(100,110):\n",
    "    print(df['English'][i])\n",
    "    print(df['Hindi'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-01-01 00:00:00'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['English'][107]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_df['english'][107].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327637, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = len(cleaned_df)\n",
    "drop_rows = []\n",
    "for ind in range(total_size):\n",
    "    if(len(cleaned_df['english'][ind].split())==0 or len(cleaned_df['hindi'][ind].split())==0):\n",
    "        drop_rows.append(ind)\n",
    "    elif(len(cleaned_df['english'][ind].split())>100 or len(cleaned_df['hindi'][ind].split())>100):\n",
    "        drop_rows.append(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327636, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.drop(drop_rows,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = cleaned_df.reset_index().drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(324562, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vocab=[]\n",
    "hin_vocab=[]\n",
    "\n",
    "for i in range(len(cleaned_df)):\n",
    "    eng_text = cleaned_df['english'][i]\n",
    "    eng_text = eng_text.split()\n",
    "    for word in eng_text:\n",
    "        if word not in eng_vocab:\n",
    "            eng_vocab.append(word)\n",
    "\n",
    "for i in range(len(cleaned_df)):\n",
    "    hin_text = cleaned_df['hindi'][i]\n",
    "    hin_text = hin_text.split()\n",
    "    for word in hin_text:\n",
    "        if word not in hin_vocab:\n",
    "            hin_vocab.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102460\n",
      "126135\n"
     ]
    }
   ],
   "source": [
    "print(len(eng_vocab))\n",
    "print(len(hin_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_eng_len = 0\n",
    "max_hin_len = 0\n",
    "\n",
    "for i in range(len(cleaned_df)):\n",
    "    eng_text = cleaned_df['english'][i]\n",
    "    if(len(eng_text.split())>max_eng_len):\n",
    "        max_eng_len = len(eng_text.split())\n",
    "\n",
    "for i in range(len(cleaned_df)):\n",
    "    hin_text = cleaned_df['hindi'][i]\n",
    "    hin_text = hin_text.split()\n",
    "    if(len(hin_text)>max_hin_len):\n",
    "        max_hin_len = len(hin_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(max_eng_len)\n",
    "print(max_hin_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_tokens = {}\n",
    "rev_eng_tokens = {}\n",
    "for ind,word in enumerate(eng_vocab):\n",
    "    eng_tokens[ind]=word\n",
    "    rev_eng_tokens[word]=ind\n",
    "    \n",
    "hin_tokens = {}\n",
    "rev_hin_tokens = {}\n",
    "for ind,word in enumerate(hin_vocab):\n",
    "    hin_tokens[ind]=word\n",
    "    rev_hin_tokens[word]=ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_tokens = len(eng_vocab)+1\n",
    "decoder_tokens = len(hin_vocab)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((292105,), (32457,))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = cleaned_df.english,cleaned_df.hindi\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 12):\n",
    "    while True:\n",
    "        # range(start, stop, step)\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object generate_batch at 0x00000178274385C8>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_batch(batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.to_csv('cleaned_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
